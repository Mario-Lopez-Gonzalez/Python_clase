{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d287d88e",
   "metadata": {
    "id": "d287d88e"
   },
   "source": [
    "# LISTA 7 - OBTENCIÓN DE DATOS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f29b17",
   "metadata": {},
   "source": [
    "## <ins>Ejercicios Obligatorios </ins>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49be9fd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting Faker\n",
      "  Downloading Faker-30.1.0-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.4 in /home/iabd/anaconda3/lib/python3.12/site-packages (from Faker) (2.9.0.post0)\n",
      "Requirement already satisfied: typing-extensions in /home/iabd/anaconda3/lib/python3.12/site-packages (from Faker) (4.11.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/iabd/anaconda3/lib/python3.12/site-packages (from python-dateutil>=2.4->Faker) (1.16.0)\n",
      "Downloading Faker-30.1.0-py3-none-any.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m29.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: Faker\n",
      "Successfully installed Faker-30.1.0\n",
      "Collecting PyMySQL\n",
      "  Downloading PyMySQL-1.1.1-py3-none-any.whl.metadata (4.4 kB)\n",
      "Downloading PyMySQL-1.1.1-py3-none-any.whl (44 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.0/45.0 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: PyMySQL\n",
      "Successfully installed PyMySQL-1.1.1\n"
     ]
    }
   ],
   "source": [
    "!pip install Faker #es una herramienta para generar datos falsos de forma automática dentro de una aplicación\n",
    "!pip install PyMySQL #permite la interacción con bases de datos MySQL\n",
    "import codecs\n",
    "from datetime import date\n",
    "from datetime import datetime\n",
    "from faker import Faker\n",
    "import pymysql\n",
    "import random\n",
    "import requests\n",
    "import csv\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f99190d1",
   "metadata": {
    "id": "f99190d1"
   },
   "source": [
    "## EJERCICIO 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "432c27ad",
   "metadata": {},
   "outputs": [
    {
     "ename": "IntegrityError",
     "evalue": "(1062, \"Duplicate entry '1' for key 'providers.PRIMARY'\")",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIntegrityError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 247\u001b[0m\n\u001b[1;32m    245\u001b[0m             str_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(entity\u001b[38;5;241m.\u001b[39mkeys()))\n\u001b[1;32m    246\u001b[0m             sql \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mINSERT INTO \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtable\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstr_columns\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) VALUES (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstr_values\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 247\u001b[0m           cur\u001b[38;5;241m.\u001b[39mexecute(sql, \u001b[38;5;28mtuple\u001b[39m(entity\u001b[38;5;241m.\u001b[39mvalues()))\n\u001b[1;32m    248\u001b[0m         con\u001b[38;5;241m.\u001b[39mcommit()\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/pymysql/cursors.py:153\u001b[0m, in \u001b[0;36mCursor.execute\u001b[0;34m(self, query, args)\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    151\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmogrify(query, args)\n\u001b[0;32m--> 153\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_query(query)\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_executed \u001b[38;5;241m=\u001b[39m query\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/pymysql/cursors.py:322\u001b[0m, in \u001b[0;36mCursor._query\u001b[0;34m(self, q)\u001b[0m\n\u001b[1;32m    320\u001b[0m conn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_db()\n\u001b[1;32m    321\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_clear_result()\n\u001b[0;32m--> 322\u001b[0m conn\u001b[38;5;241m.\u001b[39mquery(q)\n\u001b[1;32m    323\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_do_get_result()\n\u001b[1;32m    324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrowcount\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/pymysql/connections.py:563\u001b[0m, in \u001b[0;36mConnection.query\u001b[0;34m(self, sql, unbuffered)\u001b[0m\n\u001b[1;32m    561\u001b[0m     sql \u001b[38;5;241m=\u001b[39m sql\u001b[38;5;241m.\u001b[39mencode(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoding, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msurrogateescape\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    562\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_execute_command(COMMAND\u001b[38;5;241m.\u001b[39mCOM_QUERY, sql)\n\u001b[0;32m--> 563\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_affected_rows \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_read_query_result(unbuffered\u001b[38;5;241m=\u001b[39munbuffered)\n\u001b[1;32m    564\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_affected_rows\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/pymysql/connections.py:825\u001b[0m, in \u001b[0;36mConnection._read_query_result\u001b[0;34m(self, unbuffered)\u001b[0m\n\u001b[1;32m    823\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    824\u001b[0m     result \u001b[38;5;241m=\u001b[39m MySQLResult(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m--> 825\u001b[0m     result\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m    826\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result \u001b[38;5;241m=\u001b[39m result\n\u001b[1;32m    827\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result\u001b[38;5;241m.\u001b[39mserver_status \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/pymysql/connections.py:1199\u001b[0m, in \u001b[0;36mMySQLResult.read\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1197\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   1198\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1199\u001b[0m         first_packet \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconnection\u001b[38;5;241m.\u001b[39m_read_packet()\n\u001b[1;32m   1201\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m first_packet\u001b[38;5;241m.\u001b[39mis_ok_packet():\n\u001b[1;32m   1202\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_read_ok_packet(first_packet)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/pymysql/connections.py:775\u001b[0m, in \u001b[0;36mConnection._read_packet\u001b[0;34m(self, packet_type)\u001b[0m\n\u001b[1;32m    773\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\u001b[38;5;241m.\u001b[39munbuffered_active \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    774\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\u001b[38;5;241m.\u001b[39munbuffered_active \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 775\u001b[0m     packet\u001b[38;5;241m.\u001b[39mraise_for_error()\n\u001b[1;32m    776\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m packet\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/pymysql/protocol.py:219\u001b[0m, in \u001b[0;36mMysqlPacket.raise_for_error\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m DEBUG:\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merrno =\u001b[39m\u001b[38;5;124m\"\u001b[39m, errno)\n\u001b[0;32m--> 219\u001b[0m err\u001b[38;5;241m.\u001b[39mraise_mysql_exception(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/pymysql/err.py:150\u001b[0m, in \u001b[0;36mraise_mysql_exception\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m errorclass \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    149\u001b[0m     errorclass \u001b[38;5;241m=\u001b[39m InternalError \u001b[38;5;28;01mif\u001b[39;00m errno \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1000\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m OperationalError\n\u001b[0;32m--> 150\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m errorclass(errno, errval)\n",
      "\u001b[0;31mIntegrityError\u001b[0m: (1062, \"Duplicate entry '1' for key 'providers.PRIMARY'\")"
     ]
    }
   ],
   "source": [
    "NUMERO_CLIENTES = 500\n",
    "NUMERO_PROVEEDORES = 10\n",
    "SEMILLA_ALEATORIA_GENERADOR = 10\n",
    "SEMILLA_ALEATORIA_RANDOM = 1\n",
    "\n",
    "Faker.seed(SEMILLA_ALEATORIA_GENERADOR)\n",
    "random.seed(SEMILLA_ALEATORIA_RANDOM)\n",
    "fake = Faker(['es_ES'])\n",
    "\n",
    "def build_providers_dataset(number):\n",
    "  providers = []\n",
    "  for i in range(1, number+1):\n",
    "    providers.append({\n",
    "      \"provider_id\": i,\n",
    "      \"name\": fake.company(),\n",
    "      \"email\": fake.company_email(),\n",
    "      \"webpage\": fake.domain_name()\n",
    "    })\n",
    "\n",
    "  return {\n",
    "      \"providers\": providers\n",
    "  }\n",
    "\n",
    "def build_products_dataset(providers_info):\n",
    "  products = []\n",
    "  url = 'https://drive.google.com/uc?export=view&id=1D9MY0au4b7SXwhUdm6TNfsKfYzdkbAh_'\n",
    "  content = requests.get(url)\n",
    "  text = codecs.iterdecode(content.iter_lines(), 'utf-8')\n",
    "  reader = csv.DictReader(text, delimiter=',', quotechar='\"')\n",
    "  for row in reader:\n",
    "    products.append(row)\n",
    "\n",
    "  categories = sorted(set([product['category'] for product in products]))\n",
    "  categories = [{\"category_id\": i+1, \"name\": category} for (i, category) in enumerate(categories)]\n",
    "  categories_by_name = {category[\"name\"]: category[\"category_id\"] for category in categories}\n",
    "  products = [{\"product_id\": i+1, \n",
    "              \"name\": product[\"name\"], \n",
    "              \"price\": float(product[\"price\"]), \n",
    "              \"category_id\": categories_by_name[product[\"category\"]],\n",
    "              \"provider_id\": random.choice(providers_info)[\"provider_id\"]} \n",
    "              for (i, product) in enumerate(products)]\n",
    "  return {\n",
    "      'products': products,\n",
    "      'categories': categories\n",
    "  }\n",
    "\n",
    "def build_people_dataset(number):\n",
    "\n",
    "  people = []\n",
    "  addresses = []\n",
    "  payment_info = []\n",
    "  address_id = 0\n",
    "  payment_id = 0\n",
    "\n",
    "  for i in range(1, number+1):\n",
    "    # Person data\n",
    "    people.append({\n",
    "      \"person_id\": i,\n",
    "      \"first_name\": fake.first_name(),\n",
    "      \"last_name\": fake.last_name(),\n",
    "      \"birth_date\": fake.date_between_dates(datetime(1960, 1, 1), datetime(2002, 6, 1)),\n",
    "      \"email\": fake.email(),\n",
    "      \"phone\": fake.phone_number(),\n",
    "      \"username\": fake.user_name(),\n",
    "      \"password\": fake.sha256(),\n",
    "      \"job\": fake.job()\n",
    "    })\n",
    "\n",
    "    # Payment information\n",
    "    if random.choice([False]*1 + [True]*2):\n",
    "      payment_id += 1\n",
    "      payment_info.append({\n",
    "          \"payment_id\": payment_id,\n",
    "          \"person_id\": i,\n",
    "          \"expiration\": fake.credit_card_expire(),\n",
    "          \"number\": fake.credit_card_number(),\n",
    "          \"provider\": fake.credit_card_provider(),\n",
    "          \"security_code\": fake.credit_card_security_code()\n",
    "      })\n",
    "\n",
    "    # Registered addresses\n",
    "    for j in range(random.choice([1]*43 + [2]*6 + [3])):\n",
    "      address_id+=1\n",
    "      addresses.append(\n",
    "      {\n",
    "        \"address_id\": address_id,\n",
    "        \"person_id\": i,\n",
    "        \"city\": fake.city(),\n",
    "        \"number\": fake.building_number(),\n",
    "        \"country\": \"España\",\n",
    "        \"zipcode\": fake.postcode(),\n",
    "        \"street\": fake.street_name()\n",
    "      })\n",
    "\n",
    "  return {\n",
    "      \"people\": people,\n",
    "      \"addresses\": addresses,\n",
    "      \"payment_information\": payment_info,\n",
    "  }\n",
    "\n",
    "def build_network_dataset(people_info):\n",
    "\n",
    "  WEB_PAGES = [fake.uri_path() for i in range(0,100)]\n",
    "  ACCESS_METHOD_PROPORTION = ['GET'] * 10 + ['POST'] \n",
    "  pages = []\n",
    "  accesses = []\n",
    "  access_id = 0\n",
    "\n",
    "  for i in range(0, len(WEB_PAGES)):\n",
    "    pages.append({\n",
    "        \"page_id\": i+1,\n",
    "        \"path\": WEB_PAGES[i]\n",
    "    })\n",
    "\n",
    "  for person in people_info:\n",
    "    # Access to webpages\n",
    "    for j in range(int(random.gauss(60, 40))):\n",
    "      access_id += 1\n",
    "      accesses.append({\n",
    "          \"access_id\": access_id,\n",
    "          \"person_id\": person[\"person_id\"],\n",
    "          \"method\": random.choice(ACCESS_METHOD_PROPORTION),\n",
    "          \"ip\": fake.ipv4_public(),\n",
    "          \"date\": fake.date_time_between(datetime(2020,1,1,0,0,0), datetime(2020,9,1,23,59,59)),\n",
    "          \"page_id\": random.randint(1, len(WEB_PAGES)-1)\n",
    "      })\n",
    "\n",
    "  # Anonymous access\n",
    "  for i in range(int(random.gauss(1000, 100))):\n",
    "    access_id += 1\n",
    "    accesses.append({\n",
    "        \"access_id\": access_id,\n",
    "        \"person_id\": None,\n",
    "        \"method\": random.choice(ACCESS_METHOD_PROPORTION),\n",
    "        \"ip\": fake.ipv4_public(),\n",
    "        \"date\": fake.date_time_between(datetime(2020,1,1,0,0,0), datetime(2020,9,1,23,59,59)),\n",
    "        \"page_id\": random.randint(1, len(WEB_PAGES)-1)\n",
    "    })\n",
    "\n",
    "  return {\n",
    "    \"web_pages\":  pages,\n",
    "    \"accesses\": accesses\n",
    "  }\n",
    "\n",
    "def build_shopping_dataset(people, products, people_addresses):\n",
    "\n",
    "  shopping_carts = []\n",
    "  shopping_cart_products = []\n",
    "  orders = []\n",
    "  order_products = []\n",
    "  invoices = []\n",
    "  cart_id = 0\n",
    "  shopping_cart_id = 0\n",
    "  order_id = 0\n",
    "  order_product_id = 0\n",
    "  invoice_id = 0\n",
    "\n",
    "  PRODUCTS_PROBABILITY = [1]*2 + [2] * 3 + [3] * 3 + [4]*2 + [5]\n",
    "  ORDER_PROBABILITY = [0]+[1]*7+[2]*3+[3]*3+[4]*2+[5]\n",
    "  QUANTITY_PROBABILITY = [1]*5 +[2]*2 +[3]\n",
    "  RATING_PROBABILITY = [1]+[2]+[3]*2+[4]*4+[5]*3\n",
    "\n",
    "  for person in people:\n",
    "    # Build shopping cart\n",
    "    if random.choice([False * 9] + [True]):\n",
    "      cart_id += 1\n",
    "      shopping_carts.append({\n",
    "          \"cart_id\": cart_id,\n",
    "          \"person_id\": person[\"person_id\"],\n",
    "          \"date\": fake.date_time_between(datetime(2020,1,1,0,0,0), datetime(2020,9,1,23,59,59)),\n",
    "      })\n",
    "\n",
    "      chosen = random.sample(products, k = random.choice(PRODUCTS_PROBABILITY))\n",
    "      for product in chosen:\n",
    "        shopping_cart_id += 1\n",
    "        shopping_cart_products.append({\n",
    "            \"cart_id\": cart_id,\n",
    "            \"product_id\": product[\"product_id\"],\n",
    "            \"quantity\": random.choice(QUANTITY_PROBABILITY)\n",
    "        })\n",
    "    \n",
    "    # Build orders\n",
    "    for i in range(0, random.choice(ORDER_PROBABILITY)):\n",
    "      order_id += 1\n",
    "      order_price = 0\n",
    "      chosen = random.sample(products, k = random.choice(PRODUCTS_PROBABILITY))\n",
    "      for product in chosen:\n",
    "        order_product_id += 1\n",
    "        quantity = random.choice(QUANTITY_PROBABILITY)\n",
    "        order_products.append({\n",
    "            \"order_id\": order_id,\n",
    "            \"product_id\": product[\"product_id\"],\n",
    "            \"quantity\": quantity\n",
    "        })\n",
    "        order_price += quantity * product['price']\n",
    "\n",
    "      person_addresses = [address for address in people_addresses if address[\"person_id\"] == person[\"person_id\"]]\n",
    "      delivery_address = random.choice(person_addresses)\n",
    "      billing_address = random.choice(person_addresses)\n",
    "      orders.append({\n",
    "          \"order_id\": order_id,\n",
    "          \"person_id\": person[\"person_id\"],\n",
    "          \"date\": fake.date_time_between(datetime(2020,1,1,0,0,0), datetime(2020,9,1,23,59,59)),\n",
    "          # Purposely left wrong\n",
    "          \"delivery_address\": delivery_address['address_id'],\n",
    "          \"billing_address\": billing_address['address_id'],\n",
    "          \"price\": order_price\n",
    "      })\n",
    "\n",
    "  # Build invoices\n",
    "  for order in random.choices(orders, k = int(len(orders) * 0.8)):\n",
    "    invoice_id += 1\n",
    "    invoices.append({\n",
    "      \"invoice_id\": invoice_id,\n",
    "      \"order_id\": order[\"order_id\"],\n",
    "      \"date\": fake.date_time_between(order[\"date\"], datetime(2020,9,1,23,59,59)),\n",
    "      \"rating\": random.choice(RATING_PROBABILITY)\n",
    "    })\n",
    "\n",
    "  return {\n",
    "      'carts': shopping_carts,\n",
    "      'cart_product': shopping_cart_products,\n",
    "      'orders': orders,\n",
    "      'order_product': order_products,\n",
    "      'invoices': invoices    \n",
    "  }\n",
    "\n",
    "dataset = {}\n",
    "dataset.update(build_providers_dataset(NUMERO_PROVEEDORES))\n",
    "dataset.update(build_products_dataset(dataset['providers']))\n",
    "dataset.update(build_people_dataset(NUMERO_CLIENTES))\n",
    "dataset.update(build_network_dataset(dataset['people']))\n",
    "dataset.update(build_shopping_dataset(dataset['people'], dataset['products'], dataset['addresses']))\n",
    "\n",
    "con = pymysql.connect(host='localhost', user='admin',password='Password0', database='shop')\n",
    "try:\n",
    "    for table in dataset:\n",
    "      first_time = True\n",
    "      sql = \"\"\n",
    "      with con.cursor() as cur:        \n",
    "        for entity in dataset[table]:\n",
    "          if (first_time):\n",
    "            first_time = False\n",
    "            str_columns = \",\".join(entity.keys())\n",
    "            str_values = \",\".join([\"%s\"] * len(entity.keys()))\n",
    "            sql = f\"INSERT INTO {table} ({str_columns}) VALUES ({str_values})\"\n",
    "          cur.execute(sql, tuple(entity.values()))\n",
    "        con.commit()\n",
    "finally:\n",
    "    con.close()\n",
    "\n",
    "USER = \"admin\"\n",
    "PASSWORD = \"Password0\"\n",
    "HOST = \"localhost\"\n",
    "DATABASE = \"shop\"\n",
    "conn = create_engine(f'mysql+pymysql://{USER}:{PASSWORD}@{HOST}/{DATABASE}')\n",
    "pd.read_sql_query(\"SELECT * FROM products LIMIT 3\", conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f80496",
   "metadata": {},
   "source": [
    "Parece que el código pisa la base de datos creada porque no se está corriendo el script asociado, hacer que python corra el script cuando toca"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3836703",
   "metadata": {
    "id": "b3836703"
   },
   "source": [
    "La base de datos shop tiene una tabla people con información sobre los clientes de la tienda ficticia. Escribe el código Python necesario para inicializar un DataFrame con el contenido de la tabla:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d68e82b",
   "metadata": {
    "id": "4d68e82b"
   },
   "source": [
    "## EJERCICIO 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec7f3b2a",
   "metadata": {
    "id": "ec7f3b2a"
   },
   "source": [
    "La siguiente URL https://datosabiertos.carm.es/odata/Agricultura/IMIDA_dia_2018.csv contiene el informe meteorológico diario de las diferentes estaciones meteorológicas de la Región de Murcia a lo largo del año 2018. Observa el contenido del fichero csv y a continuación utiliza la función read_csv de pandas sobre esta URL con los  parámetros necesarios (header, sep, decimal, quotechar y encoding)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c943554",
   "metadata": {
    "id": "5c943554"
   },
   "source": [
    "## EJERCICIO 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2fe60bc",
   "metadata": {
    "id": "f2fe60bc"
   },
   "source": [
    "El Instituto de Salud Carlos III ofrece gratuitamente información actualizada sobre la situación del COVID-19 en España. En la siguiente URL podemos obtener un fichero csv actualizado con los casos positivos notificados por las Comunidades Autónomas a nivel provincial: https://cnecovid.isciii.es/covid19/resources/casos_diagnostico_provincia.csv. En el siguiente enlace se nos describe este conjunto de datos y se nos proporcionan otros conjuntos de datos de interés.\n",
    "\n",
    "Utiliza el método read_csv con los parámetros adecuados para obtener el DataFrame con los casos positivos por provincia. Muestra a continuación su contenido:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbbfb36c",
   "metadata": {
    "id": "cbbfb36c"
   },
   "source": [
    "## EJERCICIO 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0211a75",
   "metadata": {
    "id": "f0211a75"
   },
   "source": [
    "La siguiente URL contiene información de películas estadounidenses obtenidas de la Wikipedia en formato JSON: https://raw.githubusercontent.com/prust/wikipedia-movie-data/master/movies.json. Utiliza el método `read_json` de `pandas` para cargar su contenido en un DataFrame:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88fe1c72",
   "metadata": {
    "id": "88fe1c72"
   },
   "source": [
    "## EJERCICIO 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7446bb5",
   "metadata": {
    "id": "f7446bb5"
   },
   "source": [
    "Haciendo uso de la librería `requests` y `BeautifulSoup`, accede a la siguiente URL https://catalogoreina.com/859-grifos-cocina-roca y recupera el nombre de los artículos mostrados:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bcd805d",
   "metadata": {
    "id": "6bcd805d"
   },
   "source": [
    "## EJERCICIO 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18202d6c",
   "metadata": {
    "id": "18202d6c"
   },
   "source": [
    "Haciendo uso de la librería `requests` y `BeautifulSoup`, accede a la página web del DB-Engines https://db-engines.com/en/ranking y recupera los nombres de las 10 bases de datos más populares:\n",
    "\n",
    "PISTA: el selector CSS [`nth-child`](https://developer.mozilla.org/es/docs/Web/CSS/:nth-child) puede serte de utilidad.\n",
    "\n",
    "OTRA PISTA: para evitar que salga el contenido de la etiqueta `info` junto al nombre de la base de datos, haz uso del método [`extract`](https://www.crummy.com/software/BeautifulSoup/bs4/doc/#extract)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e60749fd",
   "metadata": {
    "id": "e60749fd"
   },
   "source": [
    "## EJERCICIO 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b12a5a",
   "metadata": {
    "id": "e7b12a5a"
   },
   "source": [
    "Haciendo uso de la librería `requests` y `BeautifulSoup`, recupera el nombre, los acabados, las medidas y el plazo de entrega del siguiente artículo: https://catalogoreina.com/nuestras-marcas-muebles-bano/10233-mueble-bano-con-patas-althea-moderno-3-cajones.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "765b822c",
   "metadata": {},
   "source": [
    "## <ins>Ejercicios Opcionales </ins>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c95369",
   "metadata": {},
   "source": [
    "## EJERCICIO 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ebf9a9",
   "metadata": {},
   "source": [
    "Esta base de datos también contiene una tabla orders con información de la cabecera de los pedidos de la tienda. En esta tabla existe una columna price que almacena el importe total del pedido. Construye a continuación un DataFrame con las cabeceras de pedidos ordenada por importe de manera descendente:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e8dcec8",
   "metadata": {},
   "source": [
    "## EJERCICIO 9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "636b544b",
   "metadata": {},
   "source": [
    "La base de datos también contiene las tablas web_pages y accesses con información de las páginas web de la empresa y de los accesos realizados a ellas respectivamente. Ambas tablas pueden relacionarse por el campo page_id. Inicializa un DataFrame que contenga los campos page_id y path de web_pages y el total de accesos realizado sobre cada una de ellas:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a2a0e3",
   "metadata": {},
   "source": [
    "## EJERCICIO 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "178aee78",
   "metadata": {},
   "source": [
    "Crea un diccionario Python que represente una factura en formato JSON:\n",
    "\n",
    "* Contendrá 4 campos cuyos valores puedes inventarte, pero siguiendo las siguientes indicaciones:\n",
    "  * **client_id**: identificador de cliente, de tipo cadena.\n",
    "  * **products**: array con al menos dos productos de tipo objeto. Cada objeto tendrá dos campos:\n",
    "    * **name**: de tipo cadena.\n",
    "    * **price**: de tipo numérico.\n",
    "  * **date**: de tipo cadena.\n",
    "  * **address**: de tipo objeto, con los siguientes campos:\n",
    "    * **street**: de tipo objeto, con los siguientes campos:\n",
    "      * **name**: de tipo cadena.\n",
    "      * **number**: de tipo numérico.\n",
    "    * **zipcode**: de tipo numérico.\n",
    "\n",
    "El diccionario tendrá que tener un formato tal que sea aceptado por el siguiente [validador](https://jsonlint.com/) de contenido JSON."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7618e719",
   "metadata": {},
   "source": [
    "## EJERCICIO 11"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24b89ce5",
   "metadata": {},
   "source": [
    "Utilizando la librería PyPDF4, recupera el número de páginas del siguiente PDF:\n",
    "```\n",
    "PDF_URL = 'https://www.mscbs.gob.es/profesionales/saludPublica/ccayes/alertasActual/nCov/documentos/Actualizacion_278_COVID-19.pdf'\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "863214e7",
   "metadata": {},
   "source": [
    "## EJERCICIO 12"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f065f31d",
   "metadata": {},
   "source": [
    "Utilizando la librería PyPDF4, recupera la fecha de creación del documento (campo /CreationDate de los metadatos):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a27f6c",
   "metadata": {},
   "source": [
    "## EJERCICIO 13"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e80dc86",
   "metadata": {},
   "source": [
    "Extrae la información del pdf en tablas y obten aquella que contiene los Detalles de los quince países con más casos confirmados fuera de Europa.\n",
    "\n",
    "PISTA: esta tabla es la última del documento PDF. Utiliza la función len para obtener el total de tablas extraídas y saber cuál de ellas seleccionar."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e31aded0",
   "metadata": {},
   "source": [
    "## EJERCICIO 14"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd167507",
   "metadata": {},
   "source": [
    "Mediante `read_excel`, carga el contenido de todas las hojas del fichero excel \"Orders-With Nulls.xlsx\", muestra el nombre de todas las hojas y muestra la hoja denominada `Summary`:"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
