{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EJERCICIOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import numpy as np\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import VotingClassifier, RandomForestClassifier,StackingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EJERCICIO 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si has entrenado cinco modelos diferentes en el mismo conjunto de entrenamiento exacto y todos consiguen una precisión del 95%, ¿hay alguna posibilidad de que puedas combinar estos modelos para obtener mejores resultados? \n",
    "\n",
    "Si la respuesta es sí, ¿cómo? Si la respuesta es no, ¿por qué?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Si, en un conjunto de votación para intentar cubrir ese 5% de fallo, dado a que cada modelo fallará en distintas áreas\n",
    "\n",
    "# Usando librerías de python como sklearn.ensemble para crear objetos que formen la pipeline de votación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EJERCICIO 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carga el conjunto de datos MNIST y divídelo en un conjunto de entrenamiento, un conjunto de validación y un conjunto de prueba (por ejemplo, utiliza 50.000 instancias para entrenamiento, 10.000 para validación y 10.000 para pruebas). \n",
    "\n",
    "Después, entrena varios clasificadores diferentes (uno de ellos que sea un árbol de decisión). \n",
    "\n",
    "A continuación, intenta combinarlos en un ensamble que supere en rendimiento a cada clasificador individual del conjunto de validación, utilizando hard voting. \n",
    "\n",
    "Una vez que hayas encontrado uno, pruébalo en el conjunto de pruebas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos el conjunto de datos\n",
    "mnist = fetch_openml('mnist_784', as_frame=False, parser=\"auto\" )\n",
    "\n",
    "# Dividimos caracteristicas del target\n",
    "X_mnist, y_mnist = mnist.data, mnist.target\n",
    "\n",
    "# Cogemos los primeros 50.000 para entrenar\n",
    "X_train, y_train = X_mnist[:50_000], y_mnist[:50_000]\n",
    "\n",
    "# Dividimos el resto\n",
    "X_valid, y_valid = X_mnist[50_000:60_000], y_mnist[50_000:60_000]\n",
    "X_test, y_test = X_mnist[60_000:], y_mnist[60_000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando  DecisionTreeClassifier(random_state=42)\n",
      "0.8822\n",
      "Entrenando  KNeighborsClassifier()\n",
      "0.9718\n",
      "Entrenando  SVC(random_state=42)\n",
      "0.9802\n"
     ]
    }
   ],
   "source": [
    "# Creamos los clasificadores\n",
    "dec_tree = DecisionTreeClassifier(random_state=42)\n",
    "knnc = KNeighborsClassifier()\n",
    "svc = SVC(random_state=42)\n",
    "\n",
    "classifiers = [dec_tree, knnc, svc]\n",
    "for classifier in classifiers:\n",
    "    print(\"Entrenando \", classifier)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    print(classifier.score(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión del conjunto de entrenamiento:  VotingClassifier(estimators=[('dec_tree',\n",
      "                              DecisionTreeClassifier(random_state=42)),\n",
      "                             ('knnc', KNeighborsClassifier()),\n",
      "                             ('svc', SVC(random_state=42))])\n",
      "Precisión del conjunto de validación:  0.9754\n"
     ]
    }
   ],
   "source": [
    "named_classifiers = [\n",
    "    (\"dec_tree\", dec_tree),\n",
    "    (\"knnc\", knnc),\n",
    "    (\"svc\", svc)\n",
    "]\n",
    "\n",
    "voting = VotingClassifier(named_classifiers)\n",
    "error_train=voting.fit(X_train, y_train)\n",
    "error_val=voting.score(X_valid, y_valid)\n",
    "print(\"Precisión del conjunto de entrenamiento: \", error_train)\n",
    "print(\"Precisión del conjunto de validación: \", error_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión del ensamble:0.9724\n"
     ]
    }
   ],
   "source": [
    "voting_score = voting.score(X_test, y_test)\n",
    "print(f\"Precisión del ensamble:{voting_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EJERCICIO 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejecuta los clasificadores individuales del ejercicio anterior para hacer predicciones en el conjunto de entrenamiento y crea un nuevo conjunto de entrenamiento con las predicciones resultantes: cada instancia de entrenamiento es un vector que contiene el conjunto de predicciones de todos tus clasificadores para una imagen y el objetivo es la clase de la imagen. Entrena un clasificador (RandomForestClassifier) en este nuevo conjunto de entrenamiento. \n",
    "\n",
    "Acabas de entrenar un blender y, junto a los clasificadores, forma un ensamble de stacking.\n",
    "\n",
    "Ahora, evalúa el ensamble en el conjunto de prueba. \n",
    "\n",
    "¿Cómo es en comparación con el clasificador de votación que has entrenado antes?\n",
    "\n",
    "Haz lo mismo usando StackingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "nav_menu": {
   "height": "252px",
   "width": "333px"
  },
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
